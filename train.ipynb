{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ea397aa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nazya/miniconda3/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import itertools\n",
    "from attrs import define\n",
    "# from code.train import train\n",
    "from codes.train import train\n",
    "from codes.optimizers import Optimizer\n",
    "# from code.problems import Problem\n",
    "from codes import Loss\n",
    "from codes.datasets import Dataset\n",
    "from codes.models import Model\n",
    "\n",
    "# %matplotlib widget\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9b5d8cd-078e-4292-97c9-0c7a02c57fbd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def zip_dict(**kwargs):\n",
    "    keys = kwargs.keys()\n",
    "    for instance in zip(*kwargs.values()):\n",
    "        yield dict(zip(keys, instance))\n",
    "\n",
    "\n",
    "def product_dict(**kwargs):\n",
    "    keys = kwargs.keys()\n",
    "    for instance in itertools.product(*kwargs.values()):\n",
    "        yield dict(zip(keys, instance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbb69728-dca1-4d11-a498-69874930542c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.environ[\"MKL_THREADING_LAYER\"] = \"AMD\"\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"TORCH_DEVICE\"] = \"cuda\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"4\"\n",
    "# os.environ[\"MKL_THREADING_LAYER\"] = \"AMD\"\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "# os.environ[\"TORCH_DEVICE\"] = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8d681b5-96b4-41e2-86af-563b88775df7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.environ['MLFLOW_VERBOSE'] = 'True'\n",
    "# os.environ['MLFLOW_CHECK_EXIST'] = 'False'\n",
    "os.environ['MLFLOW_CHECK_EXIST'] = 'True'\n",
    "os.environ['MLFLOW_EXPERIMENT_NAME'] = os.path.basename(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6563a0e6-5394-4956-ac72-fef9058294cf",
   "metadata": {},
   "source": [
    "# CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "279ed62f-ca45-4fa5-9391-85be3895f436",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 102 ms, sys: 16.3 ms, total: 118 ms\n",
      "Wall time: 117 ms\n",
      "CPU times: user 76.9 ms, sys: 32.2 ms, total: 109 ms\n",
      "Wall time: 109 ms\n",
      "CPU times: user 85.1 ms, sys: 26.8 ms, total: 112 ms\n",
      "Wall time: 112 ms\n",
      "CPU times: user 101 ms, sys: 12.1 ms, total: 113 ms\n",
      "Wall time: 113 ms\n",
      "CPU times: user 73.4 ms, sys: 36.3 ms, total: 110 ms\n",
      "Wall time: 110 ms\n",
      "CPU times: user 85.4 ms, sys: 23.5 ms, total: 109 ms\n",
      "Wall time: 109 ms\n",
      "CPU times: user 88.4 ms, sys: 20.1 ms, total: 108 ms\n",
      "Wall time: 109 ms\n",
      "CPU times: user 88.4 ms, sys: 20.1 ms, total: 109 ms\n",
      "Wall time: 109 ms\n",
      "CPU times: user 102 ms, sys: 7.68 ms, total: 110 ms\n",
      "Wall time: 110 ms\n",
      "CPU times: user 99.7 ms, sys: 11.9 ms, total: 112 ms\n",
      "Wall time: 112 ms\n",
      "CPU times: user 99.6 ms, sys: 11.9 ms, total: 111 ms\n",
      "Wall time: 112 ms\n",
      "CPU times: user 87.4 ms, sys: 23.9 ms, total: 111 ms\n",
      "Wall time: 112 ms\n",
      "CPU times: user 93.7 ms, sys: 16.3 ms, total: 110 ms\n",
      "Wall time: 110 ms\n",
      "CPU times: user 90.6 ms, sys: 19.8 ms, total: 110 ms\n",
      "Wall time: 111 ms\n",
      "CPU times: user 85.9 ms, sys: 27.6 ms, total: 113 ms\n",
      "Wall time: 114 ms\n",
      "CPU times: user 90.7 ms, sys: 23.8 ms, total: 114 ms\n",
      "Wall time: 115 ms\n",
      "CPU times: user 105 ms, sys: 8.1 ms, total: 113 ms\n",
      "Wall time: 113 ms\n",
      "CPU times: user 91.9 ms, sys: 20 ms, total: 112 ms\n",
      "Wall time: 112 ms\n",
      "CPU times: user 82.1 ms, sys: 27.6 ms, total: 110 ms\n",
      "Wall time: 110 ms\n",
      "CPU times: user 88 ms, sys: 24 ms, total: 112 ms\n",
      "Wall time: 112 ms\n",
      "CPU times: user 84.9 ms, sys: 28.2 ms, total: 113 ms\n",
      "Wall time: 113 ms\n",
      "CPU times: user 90.5 ms, sys: 19.7 ms, total: 110 ms\n",
      "Wall time: 111 ms\n",
      "CPU times: user 91.5 ms, sys: 19.9 ms, total: 111 ms\n",
      "Wall time: 111 ms\n",
      "CPU times: user 85.4 ms, sys: 24.3 ms, total: 110 ms\n",
      "Wall time: 110 ms\n",
      "CPU times: user 83 ms, sys: 27 ms, total: 110 ms\n",
      "Wall time: 109 ms\n",
      "CPU times: user 92.1 ms, sys: 20 ms, total: 112 ms\n",
      "Wall time: 113 ms\n",
      "CPU times: user 90 ms, sys: 19.6 ms, total: 110 ms\n",
      "Wall time: 110 ms\n",
      "CPU times: user 93.3 ms, sys: 12.3 ms, total: 106 ms\n",
      "Wall time: 106 ms\n",
      "CPU times: user 82.4 ms, sys: 23.7 ms, total: 106 ms\n",
      "Wall time: 106 ms\n",
      "CPU times: user 91.6 ms, sys: 15.9 ms, total: 108 ms\n",
      "Wall time: 108 ms\n",
      "CPU times: user 95.7 ms, sys: 11.9 ms, total: 108 ms\n",
      "Wall time: 108 ms\n",
      "CPU times: user 88.5 ms, sys: 20.1 ms, total: 109 ms\n",
      "Wall time: 109 ms\n",
      "CPU times: user 76.2 ms, sys: 32 ms, total: 108 ms\n",
      "Wall time: 108 ms\n",
      "CPU times: user 92.1 ms, sys: 20 ms, total: 112 ms\n",
      "Wall time: 112 ms\n",
      "CPU times: user 88.8 ms, sys: 24.2 ms, total: 113 ms\n",
      "Wall time: 113 ms\n",
      "CPU times: user 97.7 ms, sys: 11.5 ms, total: 109 ms\n",
      "Wall time: 110 ms\n"
     ]
    }
   ],
   "source": [
    "@define\n",
    "class BaseConfig():\n",
    "    nepochs:         int = 50\n",
    "    seed:            int = None\n",
    "\n",
    "    loss:           Loss = Loss.CrossEntropyLoss\n",
    "    model:         Model = Model.ResNet18\n",
    "    dataset:     Dataset = Dataset.CIFAR10\n",
    "\n",
    "    optimizer: Optimizer = None\n",
    "    batchsize:       int = 500\n",
    "    lr:            float = 1e-5\n",
    "\n",
    "    eps:           float = 1e-4\n",
    "\n",
    "    beta1_:    float = 0.9\n",
    "    beta2_:    float = 0.999\n",
    "\n",
    "    eta_:       float = None\n",
    "    \n",
    "args_grid = dict(\n",
    "    seed=[0],\n",
    "    eta_=[1e-3, 1e-1, 0],\n",
    "    eps=[1e-4, 1e-6, 1e-8, 1e-10],\n",
    ")\n",
    "\n",
    "os.environ['MLFLOW_RUN_TAGS'] = str(dict(about=f'full dataset'))\n",
    "\n",
    "for d in product_dict(**args_grid):\n",
    "\n",
    "    config = BaseConfig(**d)\n",
    "    config.optimizer = None\n",
    "    config.beta1_ = None\n",
    "    config.beta2_ = None\n",
    "    config.eta_ = None\n",
    "    os.environ['MLFLOW_RUN_NAME'] = 'AdaGrad'\n",
    "    %time train(config)\n",
    "\n",
    "    config = BaseConfig(**d)\n",
    "    config.optimizer = Optimizer.ADAM\n",
    "    config.eta_ = None\n",
    "    os.environ['MLFLOW_RUN_NAME'] = str(config.optimizer)\n",
    "    %time train(config)\n",
    "\n",
    "    config = BaseConfig(**d)\n",
    "    config.optimizer = Optimizer.KATE\n",
    "    config.beta1_ = None\n",
    "    config.beta2_ = None\n",
    "    os.environ['MLFLOW_RUN_NAME'] = str(config.optimizer)\n",
    "    %time train(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46709223-8299-4862-b635-291cddf76c5d",
   "metadata": {},
   "source": [
    "# Emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9465e9ec-6150-40f7-af5f-bfbf63d313ed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 90.4 ms, sys: 52 ms, total: 142 ms\n",
      "Wall time: 141 ms\n",
      "CPU times: user 89.4 ms, sys: 43.6 ms, total: 133 ms\n",
      "Wall time: 134 ms\n",
      "CPU times: user 92.5 ms, sys: 36.3 ms, total: 129 ms\n",
      "Wall time: 128 ms\n",
      "CPU times: user 89.3 ms, sys: 36.5 ms, total: 126 ms\n",
      "Wall time: 127 ms\n",
      "CPU times: user 107 ms, sys: 19.8 ms, total: 127 ms\n",
      "Wall time: 127 ms\n",
      "CPU times: user 97 ms, sys: 35.3 ms, total: 132 ms\n",
      "Wall time: 134 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nazya/miniconda3/lib/python3.11/site-packages/datasets/load.py:1429: FutureWarning: The repository for emotion contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/emotion\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(train_df)=16000\n",
      "len(valid_df)=2000\n",
      "len(test_df)=2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Step 2000: train-loss: 0.65920 train-accuracy: 80.44375 test-loss: 0.65817 test-accuracy: 81.25000\n",
      "CPU times: user 4min 13s, sys: 1h 12min 38s, total: 1h 16min 52s\n",
      "Wall time: 1h 16min 45s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2000: train-loss: 0.01013 train-accuracy: 99.71875 test-loss: 0.30161 test-accuracy: 92.20000\n",
      "CPU times: user 20min 14s, sys: 56min 53s, total: 1h 17min 7s\n",
      "Wall time: 1h 16min 56s\n",
      "CPU times: user 88.2 ms, sys: 48.2 ms, total: 136 ms\n",
      "Wall time: 136 ms\n",
      "CPU times: user 100 ms, sys: 32.1 ms, total: 132 ms\n",
      "Wall time: 132 ms\n",
      "CPU times: user 91.6 ms, sys: 37.1 ms, total: 129 ms\n",
      "Wall time: 129 ms\n",
      "CPU times: user 105 ms, sys: 26 ms, total: 131 ms\n",
      "Wall time: 130 ms\n",
      "CPU times: user 99.9 ms, sys: 30.7 ms, total: 131 ms\n",
      "Wall time: 131 ms\n",
      "CPU times: user 112 ms, sys: 20.2 ms, total: 132 ms\n",
      "Wall time: 132 ms\n",
      "CPU times: user 96.2 ms, sys: 36.4 ms, total: 133 ms\n",
      "Wall time: 133 ms\n",
      "CPU times: user 108 ms, sys: 26.1 ms, total: 134 ms\n",
      "Wall time: 134 ms\n",
      "CPU times: user 96.1 ms, sys: 35.6 ms, total: 132 ms\n",
      "Wall time: 132 ms\n",
      "CPU times: user 100 ms, sys: 31.4 ms, total: 131 ms\n",
      "Wall time: 131 ms\n",
      "CPU times: user 92.1 ms, sys: 40 ms, total: 132 ms\n",
      "Wall time: 132 ms\n",
      "CPU times: user 100 ms, sys: 32.3 ms, total: 133 ms\n",
      "Wall time: 133 ms\n",
      "CPU times: user 116 ms, sys: 15.4 ms, total: 131 ms\n",
      "Wall time: 132 ms\n",
      "CPU times: user 104 ms, sys: 27.1 ms, total: 131 ms\n",
      "Wall time: 131 ms\n",
      "CPU times: user 92 ms, sys: 39.5 ms, total: 132 ms\n",
      "Wall time: 132 ms\n",
      "CPU times: user 120 ms, sys: 13.4 ms, total: 133 ms\n",
      "Wall time: 133 ms\n"
     ]
    }
   ],
   "source": [
    "@define\n",
    "class BaseConfig():\n",
    "    nepochs:         int = 20\n",
    "    seed:            int = None\n",
    "\n",
    "    loss:           Loss = Loss.CrossEntropyLoss\n",
    "    model:         Model = Model.BERT\n",
    "    dataset:     Dataset = Dataset.Emotion\n",
    "\n",
    "    optimizer: Optimizer = None\n",
    "    batchsize:       int = 160\n",
    "    lr:            float = 1e-5\n",
    "\n",
    "    eps:           float = 1e-4\n",
    "\n",
    "    beta1_:    float = 0.9\n",
    "    beta2_:    float = 0.999\n",
    "\n",
    "    eta_:       float = None\n",
    "    \n",
    "    \n",
    "args_grid = dict(\n",
    "    seed=[0],\n",
    "    eta_=[1e-3, 1e-1, 0],\n",
    "    eps=[1e-4, 1e-6, 1e-8, 1e-10], #for adam and adagrad\n",
    "    # eps=[1e-3, 1e-4, 1e-5, 1e-6], #for kate\n",
    ")\n",
    "\n",
    "os.environ['MLFLOW_RUN_TAGS'] = str(dict(about=f'full dataset'))\n",
    "\n",
    "for d in product_dict(**args_grid):\n",
    "\n",
    "    config = BaseConfig(**d)\n",
    "    config.optimizer = None\n",
    "    config.beta1_ = None\n",
    "    config.beta2_ = None\n",
    "    config.eta_ = None\n",
    "    os.environ['MLFLOW_RUN_NAME'] = 'AdaGrad'\n",
    "    %time train(config)\n",
    "\n",
    "    config = BaseConfig(**d)\n",
    "    config.optimizer = Optimizer.ADAM\n",
    "    config.eta_ = None\n",
    "    os.environ['MLFLOW_RUN_NAME'] = str(config.optimizer)\n",
    "    %time train(config)\n",
    "\n",
    "    # config = BaseConfig(**d)\n",
    "    # config.optimizer = Optimizer.KATE\n",
    "    # # config.eps = 1e-4\n",
    "    # config.beta1_ = None\n",
    "    # config.beta2_ = None\n",
    "    # os.environ['MLFLOW_RUN_NAME'] = str(config.optimizer)\n",
    "    # %time train(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6fbdf45-2895-484f-9f43-6277729657d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef36146-3711-4ee6-8e06-2e0a36550ecd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42054316-2b06-4b8c-98b0-dac65b172f15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc-autonumbering": true,
  "toc-showcode": true,
  "vscode": {
   "interpreter": {
    "hash": "18f7a5ae47153a9b42c5447ccb1bbe68959e117ab7750209e163c7c253c9e013"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
